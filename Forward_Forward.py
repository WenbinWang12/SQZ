import math
import random
import numpy as np
import os
import matplotlib.pyplot as plt
from dataclasses import dataclass
from typing import List, Tuple, Optional


import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader
from torchvision import datasets, transforms
from torchvision.utils import make_grid

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
from sklearn.manifold import TSNE


# =============== æ ¸å¿ƒï¼šFFå±‚å®šä¹‰ ===============
class FFLayer(nn.Module):
    """
    å•ä¸ª Forward-Forward çº¿æ€§å±‚ï¼šh = relu(x W + b)
    goodness = mean(h^2)  (å¯¹æ¯ä¸ªæ ·æœ¬é€å±‚è®¡ç®—ï¼Œå†å– batch å¹³å‡)
    """
    def __init__(self, in_dim: int, out_dim: int, bias: bool = True):
        super().__init__()
        self.linear = nn.Linear(in_dim, out_dim, bias=bias)
        # Hinton åŸæ–‡å»ºè®® ReLU + squared activationsï¼›ä½ ä¹Ÿå¯å°è¯• SiLU/Tanh ç­‰
        self.act = nn.ReLU()

        # å‚æ•°åˆå§‹åŒ–ï¼ˆå¯æŒ‰éœ€å¾®è°ƒï¼‰
        nn.init.kaiming_normal_(self.linear.weight, nonlinearity="relu")
        if bias and self.linear.bias is not None:
            nn.init.zeros_(self.linear.bias)

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        return self.act(self.linear(x))

    @staticmethod
    def goodness(h: torch.Tensor) -> torch.Tensor:
        # å¯¹æ¯ä¸ªæ ·æœ¬ï¼šgoodness_i = mean_j h_{ij}^2
        return (h ** 2).mean(dim=1)


# =============== ç½‘ç»œå°è£…ï¼ˆè‹¥å¹²å±‚ä¸²è”ï¼‰ ===============
class FFNet(nn.Module):
    """
    è‹¥å¹² FFLayer ä¸²è”ã€‚è®­ç»ƒ/æ¨æ–­å‡â€œæ— åä¼ â€ï¼Œæ¯å±‚å±€éƒ¨åˆ¤åˆ«ã€‚
    ç›‘ç£æ–¹å¼ï¼šæŠŠ label one-hot æ‹¼åˆ°è¾“å…¥ä¸Šï¼ˆclass-conditional è¾“å…¥ï¼‰ï¼Œ
    æ­£æ ·æœ¬ï¼šçœŸå®æ ‡ç­¾ï¼Œè´Ÿæ ·æœ¬ï¼šéšæœºé”™è¯¯æ ‡ç­¾ã€‚
    """
    def __init__(self, input_dim: int, layers: List[int], num_classes: int):
        super().__init__()
        self.num_classes = num_classes

        dims = [input_dim + num_classes] + layers  # ç¬¬ä¸€å±‚è¾“å…¥æ‹¼ä¸Š one-hot æ ‡ç­¾
        self.layers = nn.ModuleList([FFLayer(dims[i], dims[i + 1]) for i in range(len(dims) - 1)])

    def forward_through_layers(self, x: torch.Tensor) -> List[torch.Tensor]:
        """
        è¿”å›å„å±‚çš„æ¿€æ´»ç»“æœï¼Œä¾¿äºé€å±‚è®¡ç®— goodnessã€‚
        """
        hs = []
        h = x
        for layer in self.layers:
            h = layer(h)
            hs.append(h)
        return hs

    @torch.no_grad()
    def classify(self, x: torch.Tensor) -> torch.Tensor:
        """
        æ¨æ–­ï¼šå¯¹æ¯ä¸ªç±» cï¼Œæ„é€  [x, one_hot(c)]ï¼Œå‰å‘é€šè¿‡æ‰€æœ‰å±‚ï¼Œç´¯åŠ  goodnessï¼Œå– argmaxã€‚
        x shape: (B, D_in)
        return: é¢„æµ‹æ ‡ç­¾ (B,)
        """
        B = x.size(0)
        device = x.device
        scores = torch.zeros(B, self.num_classes, device=device)

        for c in range(self.num_classes):
            onehot = F.one_hot(torch.full((B,), c, device=device), num_classes=self.num_classes).float()
            xc = torch.cat([x, onehot], dim=1)
            hs = self.forward_through_layers(xc)
            # ç´¯åŠ æ‰€æœ‰å±‚çš„ goodness ä½œä¸ºè¯¥ç±»çš„æ‰“åˆ†
            score_c = torch.stack([FFLayer.goodness(h) for h in hs], dim=1).sum(dim=1)
            scores[:, c] = score_c

        return scores.argmax(dim=1)


# =============== è®­ç»ƒä¾‹ç¨‹ï¼ˆé€å±‚ FF è®­ç»ƒï¼‰ ===============
@dataclass
class FFTrainConfig:
    epochs_per_layer: int = 2
    lr: float = 1e-3
    margin: float = 2.0     # æ­£è´Ÿ goodness çš„é—´éš”ï¼ˆbï¼Œè¶Šå¤§è¶Šä¸¥æ ¼ï¼‰
    device: str = "cuda" if torch.cuda.is_available() else "cpu"


def make_pos_neg_pairs(x_flat: torch.Tensor, y: torch.Tensor, num_classes: int) -> Tuple[torch.Tensor, torch.Tensor]:
    """
    æ„é€ ç›‘ç£å¼çš„æ­£/è´Ÿæ ·æœ¬å¯¹ï¼š
      - æ­£ï¼šæ‹¼æ¥çœŸå®æ ‡ç­¾çš„ one-hot
      - è´Ÿï¼šä¸ºæ¯ä¸ªæ ·æœ¬éšæœºé‡‡æ ·ä¸€ä¸ªé”™è¯¯æ ‡ç­¾ï¼Œæ‹¼æ¥å…¶ one-hot
    """
    B, Din = x_flat.shape
    device = x_flat.device

    # æ­£æ ·æœ¬
    y_pos = F.one_hot(y, num_classes=num_classes).float()
    x_pos = torch.cat([x_flat, y_pos], dim=1)

    # è´Ÿæ ·æœ¬ï¼ˆéšæœºé”™è¯¯æ ‡ç­¾ï¼‰
    y_neg_idx = []
    for i in range(B):
        wrong = random.randrange(num_classes - 1)
        if wrong >= y[i].item():
            wrong += 1
        y_neg_idx.append(wrong)
    y_neg = F.one_hot(torch.tensor(y_neg_idx, device=device), num_classes=num_classes).float()
    x_neg = torch.cat([x_flat, y_neg], dim=1)

    return x_pos, x_neg


def ff_layer_train_step(layer: FFLayer,
                        x_pos: torch.Tensor,
                        x_neg: torch.Tensor,
                        optimizer: torch.optim.Optimizer,
                        margin: float) -> float:
    """
    å•å±‚çš„ FF æŸå¤±ï¼š
      L = - [ log Ïƒ(good_pos - b) + log (1 - Ïƒ(good_neg - b)) ]
      è¿™é‡Œ b=marginã€‚æŠŠ goodness å½“äºŒåˆ†ç±»æ‰“åˆ†ï¼ˆæ­£åº”å¤§ã€è´Ÿåº”å°ï¼‰ã€‚
    """
    layer.train()
    optimizer.zero_grad()

    h_pos = layer(x_pos)
    h_neg = layer(x_neg)

    g_pos = FFLayer.goodness(h_pos)  # (B,)
    g_neg = FFLayer.goodness(h_neg)  # (B,)

    # logistic åˆ¤åˆ«ç›®æ ‡ï¼ˆå¯æ›¿æ¢ä¸º hinge/margin loss ç­‰ï¼‰
    loss = - (torch.log(torch.sigmoid(g_pos - margin)) + torch.log(1 - torch.sigmoid(g_neg - margin))).mean()
    loss.backward()           # è¿™é‡Œå¯¹è¯¥å±‚åšä¸€æ¬¡åä¼ ï¼ˆä½†**ä¸**è·¨å±‚ä¼ æ’­ï¼‰ï¼Œä½“ç°â€œå±€éƒ¨å¯å­¦ä¹ â€
    optimizer.step()

    return loss.item()


def ff_train_layerwise(model: FFNet,
                       train_loader: DataLoader,
                       cfg: FFTrainConfig) -> None:
    device = cfg.device
    model.to(device)

    for li, layer in enumerate(model.layers):
        # åªè®­ç»ƒå½“å‰å±‚
        for p in model.layers.parameters():
            p.requires_grad_(False)
        for p in layer.parameters():
            p.requires_grad_(True)

        optimizer = torch.optim.Adam(layer.parameters(), lr=cfg.lr)

        for epoch in range(cfg.epochs_per_layer):
            running = 0.0
            n = 0
            for x, y in train_loader:
                x = x.to(device)
                y = y.to(device)
                x_flat = x.view(x.size(0), -1)

                if li == 0:
                    # ç¬¬0å±‚ï¼šè¿™é‡Œæ‰éœ€è¦æ‹¼ one-hot
                    x_pos, x_neg = make_pos_neg_pairs(x_flat, y, model.num_classes)
                else:
                    # æ›´æ·±å±‚ï¼šå…ˆåœ¨å†»ç»“çš„å‰ li å±‚ä¸Šå‰å‘ï¼Œå¾—åˆ°ç¬¬ li å±‚çš„æ­£/è´Ÿè¾“å…¥
                    with torch.no_grad():
                        x_pos0, x_neg0 = make_pos_neg_pairs(x_flat, y, model.num_classes)
                        h_pos, h_neg = x_pos0, x_neg0
                        for j in range(li):
                            h_pos = model.layers[j](h_pos)
                            h_neg = model.layers[j](h_neg)
                    # ä¸å†æ‹¼æ ‡ç­¾ï¼Œç›´æ¥ä½œä¸ºå½“å‰å±‚è¾“å…¥
                    x_pos, x_neg = h_pos, h_neg

                loss = ff_layer_train_step(layer, x_pos, x_neg, optimizer, cfg.margin)
                running += loss * x.size(0)
                n += x.size(0)

            print(f"[Layer {li+1}/{len(model.layers)}] Epoch {epoch+1}/{cfg.epochs_per_layer}  "
                  f"loss={running / n:.4f}")



@torch.no_grad()
def evaluate(model: FFNet, data_loader: DataLoader) -> float:
    model.eval()
    device = next(model.parameters()).device
    correct = 0
    total = 0
    for x, y in data_loader:
        x = x.to(device)
        y = y.to(device)
        x_flat = x.view(x.size(0), -1)
        yhat = model.classify(x_flat)
        correct += (yhat == y).sum().item()
        total += y.size(0)
    return correct / total


# =============== æ•°æ® & è®­ç»ƒè„šæœ¬ ===============
def get_dataloaders(batch_size=256, num_workers=0, pin_memory=None):
    """
    Windows ä¸Šå…ˆç”¨ num_workers=0ï¼Œç¡®è®¤è·‘é€šåå†å°è¯• >0ã€‚
    Normalize((0.5,), (0.5,)) ç­‰ä»·äº t*2-1ï¼Œé¿å…äº† Lambda çš„ pickle é—®é¢˜ã€‚
    """
    if pin_memory is None:
        # åªæœ‰åœ¨ç”¨ GPU æ—¶å†å¯ç”¨ pin_memory æ¯”è¾ƒæœ‰æ„ä¹‰
        pin_memory = torch.cuda.is_available()

    tfm = transforms.Compose([
        transforms.ToTensor(),                     # [0,1]
        transforms.Normalize((0.5,), (0.5,)),      # æ˜ å°„åˆ° [-1,1]ï¼Œæ—  lambda
    ])

    train = datasets.MNIST(root="./data", train=True,  download=True, transform=tfm)
    test  = datasets.MNIST(root="./data", train=False, download=True, transform=tfm)

    train_loader = DataLoader(
        train, batch_size=batch_size, shuffle=True,
        num_workers=num_workers, pin_memory=pin_memory,
        persistent_workers=False  # Windows å»ºè®®å…³æ‰
    )
    test_loader = DataLoader(
        test, batch_size=batch_size, shuffle=False,
        num_workers=num_workers, pin_memory=pin_memory,
        persistent_workers=False
    )
    return train_loader, test_loader



def main():
    torch.manual_seed(0)
    train_loader, test_loader = get_dataloaders(batch_size=256, num_workers=0)

    # MNIST: 28*28 è¾“å…¥ï¼›åˆ†ç±»æ•° 10ï¼›ç»™ä¸€ä¸ªå°çš„å¤šå±‚ç½‘ç»œ
    input_dim = 28 * 28
    num_classes = 10
    layers = [1024, 512]  # ä½ å¯ä»¥åŠ æ·±/å˜å®½

    model = FFNet(input_dim=input_dim, layers=layers, num_classes=num_classes)

    cfg = FFTrainConfig(
        epochs_per_layer=2,   # æ¼”ç¤ºç”¨ï¼Œå®é™…å¯è°ƒå¤§
        lr=1e-3,
        margin=2.0,
        device="cuda" if torch.cuda.is_available() else "cpu",
    )

    ff_train_layerwise(model, train_loader, cfg)

    acc = evaluate(model, test_loader)
    print(f"Test accuracy: {acc*100:.2f}%")

    # # === å¯è§†åŒ– 1ï¼šæ··æ·†çŸ©é˜µ ===
    # plot_confusion_matrix(model, test_loader, class_names=[str(i) for i in range(10)])

    # # === å¯è§†åŒ– 2ï¼šé”™åˆ†æ ·æœ¬ç½‘æ ¼ ===
    # show_misclassified_grid(model, test_loader, num_samples=25, denormalize=True)

    # # === å¯è§†åŒ– 3ï¼šgoodness ç›´æ–¹å›¾ï¼ˆç¬¬1å±‚ï¼›å¯æ”¹æˆ 1 è¡¨ç¤ºç¬¬2å±‚ï¼‰ ===
    # plot_goodness_histogram(model, test_loader, layer_index=0, num_batches=2, bins=40)

    # === å¯è§†åŒ– 4ï¼št-SNEï¼ˆæœ€åä¸€å±‚ï¼›å¯æ”¹ layer_index=0 çœ‹ç¬¬1å±‚ï¼‰===
    plot_tsne_activations(model, test_loader, layer_index=0, sample_size=2000, perplexity=30.0)

    # ä¸º 10 ä¸ªç±»åˆ«å„ç”Ÿæˆ 1 å¼ ï¼ˆ10x1 çš„ç½‘æ ¼ï¼‰
    _ = visualize_generation(
        model,
        classes_to_generate=list(range(10)),  # 0..9
        per_class=1,                          # æ¯ç±»ç”Ÿæˆå‡ å¼ 
        steps=200,                            # æ¢¯åº¦ä¸Šå‡æ­¥æ•°ï¼Œå¯è°ƒ 100~500
        lr=0.1,                               # å­¦ä¹ ç‡ï¼›è¾ƒå¤§æ—¶å®¹æ˜“ç³Šï¼Œè¾ƒå°æ—¶æ”¶æ•›æ…¢
        tv_weight=0.002,                      # TV æ­£åˆ™ï¼›è¶Šå¤§è¶Šå¹³æ»‘ï¼Œä½†ä¹Ÿå¯èƒ½å¤±çœŸ
        l2_weight=0.0,                        # L2 æ­£åˆ™ï¼›ä¸€èˆ¬å¯ 0ï¼Œå¦‚ä¸ç¨³å®šå¯åŠ  1e-4~1e-3
        img_h=28, img_w=28,                   # MNIST
        save_path="./ff_generations/ff_gen_10x1.png",
        show=True
    )

@torch.no_grad()
def _gather_preds(model, data_loader, device) -> Tuple[np.ndarray, np.ndarray]:
    model.eval()
    y_true, y_pred = [], []
    for x, y in data_loader:
        x = x.to(device)
        y = y.to(device)
        x_flat = x.view(x.size(0), -1)
        preds = model.classify(x_flat)
        y_true.append(y.cpu().numpy())
        y_pred.append(preds.cpu().numpy())
    y_true = np.concatenate(y_true, axis=0)
    y_pred = np.concatenate(y_pred, axis=0)
    return y_true, y_pred


# 1) æ··æ·†çŸ©é˜µ
def plot_confusion_matrix(model, data_loader, class_names: Optional[List[str]] = None):
    device = next(model.parameters()).device
    y_true, y_pred = _gather_preds(model, data_loader, device)

    if class_names is None:
        num_classes = int(np.max(y_true)) + 1
        class_names = list(map(str, range(num_classes)))

    cm = confusion_matrix(y_true, y_pred, labels=list(range(len(class_names))))
    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)
    fig, ax = plt.subplots(figsize=(6, 6))
    disp.plot(cmap="Blues", ax=ax, colorbar=True)
    ax.set_title("Confusion Matrix")
    plt.tight_layout()
    plt.show()


# 2) é”™åˆ†æ ·æœ¬ç½‘æ ¼ï¼ˆæ˜¾ç¤ºåŸå›¾ã€çœŸå®/é¢„æµ‹æ ‡ç­¾ï¼‰
@torch.no_grad()
def show_misclassified_grid(model,
                            data_loader,
                            num_samples: int = 25,
                            denormalize: bool = True):
    """
    num_samples: å±•ç¤ºçš„é”™åˆ†ä¸ªæ•°ï¼ˆå°½é‡å‡‘å¤Ÿï¼‰
    denormalize: å¦‚æœä½ åœ¨ ToTensor ååšäº† Normalize((0.5,), (0.5,)),
                 è¿™é‡Œåšä¸€æ¬¡åå˜æ¢ï¼ŒæŠŠ [-1,1] æ˜¾ç¤ºå› [0,1]
    """
    device = next(model.parameters()).device
    model.eval()
    mis_imgs, mis_true, mis_pred = [], [], []

    for x, y in data_loader:
        x = x.to(device)
        y = y.to(device)
        B = x.size(0)
        preds = model.classify(x.view(B, -1))

        mask = (preds != y)
        if mask.any():
            idxs = torch.where(mask)[0]
            for i in idxs:
                mis_imgs.append(x[i].detach().cpu())   # (1, H, W)
                mis_true.append(int(y[i].item()))
                mis_pred.append(int(preds[i].item()))
                if len(mis_imgs) >= num_samples:
                    break
        if len(mis_imgs) >= num_samples:
            break

    if len(mis_imgs) == 0:
        print("No misclassified samples found on this split. ğŸ‰")
        return

    # åå½’ä¸€åŒ–å› [0,1] æ–¹ä¾¿æ˜¾ç¤º
    if denormalize:
        mis_imgs = [(img * 0.5 + 0.5).clamp(0, 1) for img in mis_imgs]

    cols = int(math.ceil(math.sqrt(len(mis_imgs))))
    rows = int(math.ceil(len(mis_imgs) / cols))
    fig, axes = plt.subplots(rows, cols, figsize=(1.8*cols, 1.8*rows))
    axes = np.array(axes).reshape(rows, cols)

    for k in range(rows * cols):
        r, c = divmod(k, cols)
        ax = axes[r, c]
        ax.axis("off")
        if k < len(mis_imgs):
            img = mis_imgs[k].squeeze(0).numpy()  # (H, W)
            ax.imshow(img, cmap="gray")
            ax.set_title(f"T:{mis_true[k]} / P:{mis_pred[k]}", fontsize=9)
    fig.suptitle("Misclassified Samples", y=0.98)
    plt.tight_layout()
    plt.show()


# 3) æŒ‡å®šå±‚çš„ goodness ç›´æ–¹å›¾ï¼ˆæ­£/è´Ÿæ ·æœ¬ï¼‰
@torch.no_grad()
def plot_goodness_histogram(model,
                            data_loader,
                            layer_index: int = 0,
                            num_batches: int = 1,
                            bins: int = 40):
    """
    layer_index: é€‰æ‹©ç¬¬å‡ å±‚çš„ goodnessï¼ˆ0-basedï¼‰
    num_batches: ä» data_loader å–å¤šå°‘ä¸ª batch èšåˆç»˜å›¾
    """
    device = next(model.parameters()).device
    model.eval()

    gpos_all, gneg_all = [], []
    it = iter(data_loader)
    taken = 0
    while taken < num_batches:
        try:
            x, y = next(it)
        except StopIteration:
            break
        taken += 1

        x = x.to(device)
        y = y.to(device)
        x_flat = x.view(x.size(0), -1)

        # æ„é€ æ­£/è´Ÿè¾“å…¥ï¼ˆä¸è®­ç»ƒä¸€è‡´ï¼‰
        x_pos0, x_neg0 = make_pos_neg_pairs(x_flat, y, model.num_classes)

        # é€šè¿‡åˆ°æŒ‡å®šå±‚çš„è¾“å…¥ï¼šè‹¥å±‚ç´¢å¼• > 0ï¼Œéœ€è¦å…ˆè¿‡å‰å‡ å±‚
        h_pos, h_neg = x_pos0, x_neg0
        for j in range(layer_index):
            h_pos = model.layers[j](h_pos)
            h_neg = model.layers[j](h_neg)

        # åœ¨è¯¥å±‚ä¸Šå‰å‘ä¸€æ¬¡ï¼Œç®— goodness
        h_pos = model.layers[layer_index](h_pos)
        h_neg = model.layers[layer_index](h_neg)

        g_pos = (h_pos ** 2).mean(dim=1).cpu().numpy()
        g_neg = (h_neg ** 2).mean(dim=1).cpu().numpy()

        gpos_all.append(g_pos)
        gneg_all.append(g_neg)

    if not gpos_all:
        print("No batches available.")
        return

    gpos = np.concatenate(gpos_all, axis=0)
    gneg = np.concatenate(gneg_all, axis=0)

    plt.figure(figsize=(6, 4))
    plt.hist(gpos, bins=bins, alpha=0.6, label="Positive")
    plt.hist(gneg, bins=bins, alpha=0.6, label="Negative")
    plt.xlabel("Goodness")
    plt.ylabel("Count")
    plt.title(f"Goodness Distribution (Layer {layer_index+1})")
    plt.legend()
    plt.tight_layout()
    plt.show()


# 4) æŒ‡å®šå±‚æ¿€æ´»çš„ t-SNE å¯è§†åŒ–
@torch.no_grad()
def plot_tsne_activations(model,
                          data_loader,
                          layer_index: int = -1,
                          sample_size: int = 2000,
                          perplexity: float = 30.0,
                          random_state: int = 0):
    """
    layer_index: -1 è¡¨ç¤ºæœ€åä¸€å±‚ï¼›å¦åˆ™é€‰å®š 0-based å±‚ç´¢å¼•
    sample_size: ä»æµ‹è¯•é›†ä¸­æŠ½æ ·çš„æ ·æœ¬æ•°ï¼ˆå¤ªå¤§ä¼šå¾ˆæ…¢ï¼‰
    """
    device = next(model.parameters()).device
    model.eval()

    xs, ys = [], []
    cnt = 0
    for x, y in data_loader:
        x = x.to(device)
        y = y.to(device)
        xs.append(x)
        ys.append(y)
        cnt += x.size(0)
        if cnt >= sample_size:
            break

    x = torch.cat(xs, dim=0)[:sample_size]
    y = torch.cat(ys, dim=0)[:sample_size]
    x_flat = x.view(x.size(0), -1)

    # ä»…ç”¨â€œæ­£æ ·æœ¬æ„é€ â€çš„è¾“å…¥ï¼Œä»¥åŒ¹é…æ¨æ–­ä½¿ç”¨
    x_pos, _ = make_pos_neg_pairs(x_flat, y, model.num_classes)

    # å‰å‘åˆ°æŒ‡å®šå±‚
    if layer_index < 0:
        layer_index = len(model.layers) - 1

    h = x_pos
    for j in range(layer_index + 1):
        h = model.layers[j](h)

    H = h.detach().cpu().numpy()
    y_np = y.detach().cpu().numpy()

    # t-SNE
    tsne = TSNE(n_components=2, perplexity=perplexity, random_state=random_state, init="pca")
    H2 = tsne.fit_transform(H)

    plt.figure(figsize=(6, 5))
    sc = plt.scatter(H2[:, 0], H2[:, 1], c=y_np, cmap="tab10", s=10)
    cbar = plt.colorbar(sc, ticks=list(range(int(y_np.max())+1)))
    cbar.ax.set_ylabel("Class")
    plt.title(f"t-SNE of Activations (Layer {layer_index+1})")
    plt.tight_layout()
    plt.show()


# -------------------- æ˜¾ç¤º/ä¿å­˜ç”¨çš„å°å·¥å…· --------------------
def _to_display_range(x: torch.Tensor) -> torch.Tensor:
    """
    è®­ç»ƒæ—¶æˆ‘ä»¬æŠŠåƒç´ æ”¾åœ¨ [-1,1]ï¼Œæ˜¾ç¤ºæ—¶è½¬å› [0,1]
    x: (B, 1, H, W) æˆ– (B, H, W)
    """
    y = (x + 1.0) / 2.0
    return y.clamp(0, 1)

def save_image_grid(tensor: torch.Tensor, nrow: int, save_path: str):
    """
    tensor: (B, 1, H, W) in [-1, 1]
    """
    os.makedirs(os.path.dirname(save_path), exist_ok=True)
    grid = make_grid(_to_display_range(tensor), nrow=nrow, padding=2)
    plt.figure(figsize=(nrow * 1.6, math.ceil(tensor.size(0) / nrow) * 1.6))
    plt.axis("off")
    plt.imshow(grid.permute(1, 2, 0).cpu().numpy(), interpolation="nearest")
    plt.tight_layout()
    plt.savefig(save_path, dpi=200, bbox_inches="tight", pad_inches=0.05)
    plt.close()

def show_image_grid(tensor: torch.Tensor, nrow: int, title: str = None):
    grid = make_grid(_to_display_range(tensor), nrow=nrow, padding=2)
    plt.figure(figsize=(nrow * 1.6, math.ceil(tensor.size(0) / nrow) * 1.6))
    if title:
        plt.title(title)
    plt.axis("off")
    plt.imshow(grid.permute(1, 2, 0).cpu().numpy(), interpolation="nearest")
    plt.show()


# -------------------- æ­£åˆ™ï¼šTotal Variation (TV) --------------------
def total_variation(x: torch.Tensor, height: int, width: int) -> torch.Tensor:
    """
    x: (B, D) in [-1,1]ï¼ŒæŠŠå®ƒ reshape æˆ (B,1,H,W) åš TV
    """
    B, D = x.shape
    img = x.view(B, 1, height, width)
    tv_h = (img[:, :, 1:, :] - img[:, :, :-1, :]).pow(2).mean()
    tv_w = (img[:, :, :, 1:] - img[:, :, :, :-1]).pow(2).mean()
    return tv_h + tv_w


# -------------------- è®¡ç®— FF å¾—åˆ†ï¼ˆå„å±‚ goodness ä¹‹å’Œï¼‰ --------------------
@torch.no_grad()
def ff_class_score(model, x_flat: torch.Tensor, label_ids: torch.Tensor) -> torch.Tensor:
    """
    ä»…ç”¨äºè¯„ä¼°ï¼šå¯¹æ¯ä¸ªæ ·æœ¬ cï¼Œæ‹¼ one-hotï¼Œç»æ‰€æœ‰å±‚ï¼Œè¿”å› goodness æ€»å’Œã€‚
    x_flat: (B, D)
    label_ids: (B,) int64 in [0, num_classes)
    """
    B = x_flat.size(0)
    onehot = F.one_hot(label_ids, num_classes=model.num_classes).float().to(x_flat.device)
    xc = torch.cat([x_flat, onehot], dim=1)
    hs = model.forward_through_layers(xc)
    score = torch.stack([FFLayer.goodness(h) for h in hs], dim=1).sum(dim=1)
    return score


# -------------------- ç”Ÿæˆï¼šå¯¹è¾“å…¥åšæ¢¯åº¦ä¸Šå‡ï¼Œæœ€å¤§åŒ– goodness --------------------
def generate_ff_images(model,
                       target_labels,
                       steps: int = 200,
                       lr: float = 0.1,
                       tv_weight: float = 0.001,
                       l2_weight: float = 0.0,
                       init: str = "noise",
                       img_h: int = 28,
                       img_w: int = 28,
                       verbose: bool = True):
    """
    å‚æ•°ï¼š
      - model: è®­ç»ƒå¥½çš„ FFNet
      - target_labels: é•¿åº¦ä¸º B çš„ list/ndarray/LongTensorï¼Œè¡¨ç¤ºè¦ç”Ÿæˆçš„ç±»åˆ«
      - steps: æ¢¯åº¦ä¸Šå‡æ­¥æ•°
      - lr: å­¦ä¹ ç‡ï¼ˆå»ºè®® 0.05~0.2 ä¹‹é—´å°è¯•ï¼‰
      - tv_weight: TV æ­£åˆ™å¼ºåº¦ï¼ˆå»å™ª/å¹³æ»‘ï¼‰
      - l2_weight: L2 æ­£åˆ™å¼ºåº¦ï¼ˆé˜²å‘æ•£ï¼Œå¯è®¾ 0ï¼‰
      - init: åˆå§‹åŒ–æ–¹å¼ {"noise", "zeros", "gaussian"}
      - img_h, img_w: å›¾åƒå°ºå¯¸ï¼ˆMNIST ä¸º 28Ã—28ï¼‰

    è¿”å›ï¼š
      - imgs: (B, 1, H, W) in [-1, 1]
      - history (å¯é€‰): è®°å½•æ¯æ­¥çš„å¹³å‡ scoreï¼ˆä¾¿äºç”»æ”¶æ•›æ›²çº¿ï¼‰
    """
    device = next(model.parameters()).device
    model.eval()

    if isinstance(target_labels, torch.Tensor):
        labels = target_labels.to(device).long()
    else:
        labels = torch.tensor(target_labels, device=device, dtype=torch.long)

    B = labels.size(0)
    D = img_h * img_w

    # åˆå§‹åŒ–è¾“å…¥
    if init == "noise":
        x = torch.empty(B, D, device=device).uniform_(-1.0, 1.0)
    elif init == "gaussian":
        x = torch.randn(B, D, device=device).clamp_(-2.0, 2.0) / 2.0
        x = x.tanh()  # å¤§è‡´è½åœ¨ [-1,1]
    elif init == "zeros":
        x = torch.zeros(B, D, device=device)
    else:
        raise ValueError("init must be one of {'noise','gaussian','zeros'}")

    x.requires_grad_(True)
    optimizer = torch.optim.Adam([x], lr=lr)

    score_trace = []

    for t in range(steps):
        optimizer.zero_grad()

        # æ‹¼ one-hotï¼Œå‰å‘é€šè¿‡æ‰€æœ‰å±‚ï¼Œç´¯è®¡ goodness
        onehot = F.one_hot(labels, num_classes=model.num_classes).float()
        inp = torch.cat([x, onehot], dim=1)
        hs = model.forward_through_layers(inp)
        score = torch.stack([FFLayer.goodness(h) for h in hs], dim=1).sum(dim=1)   # (B,)

        # æ­£åˆ™
        tv = total_variation(x, img_h, img_w) if tv_weight > 0 else x.new_tensor(0.0)
        l2 = x.pow(2).mean() if l2_weight > 0 else x.new_tensor(0.0)

        # æˆ‘ä»¬åšâ€œæœ€å¤§åŒ–â€ï¼Œæ‰€ä»¥ç”¨è´Ÿå·å½“ä½œæŸå¤±
        loss = -(score.mean() - tv_weight * tv - l2_weight * l2)
        loss.backward()
        optimizer.step()

        # å°†åƒç´ ä¿æŒåœ¨è®­ç»ƒåŸŸ [-1,1]
        with torch.no_grad():
            x.clamp_(-1.0, 1.0)

        score_trace.append(score.mean().item())
        if verbose and (t % max(1, steps // 10) == 0 or t == steps - 1):
            print(f"[Gen] step {t+1:4d}/{steps}, avg_score={score_trace[-1]:.4f}, "
                  f"tv={tv.item():.5f}, l2={l2.item():.5f}")

    imgs = x.view(B, 1, img_h, img_w).detach()
    return imgs, score_trace


# -------------------- ä¸€é”®å¯è§†åŒ–ï¼ˆæ˜¾ç¤º+ä¿å­˜ï¼‰ --------------------
def visualize_generation(model,
                         classes_to_generate=None,
                         per_class: int = 1,
                         steps: int = 200,
                         lr: float = 0.1,
                         tv_weight: float = 0.001,
                         l2_weight: float = 0.0,
                         img_h: int = 28,
                         img_w: int = 28,
                         save_path: str = "./ff_generations/ff_gen.png",
                         show: bool = True):
    """
    ä¸ºè‹¥å¹²ç±»åˆ«å„ç”Ÿæˆ per_class å¼ ï¼Œç½‘æ ¼æ˜¾ç¤ºå¹¶ä¿å­˜ã€‚
    """
    if classes_to_generate is None:
        classes_to_generate = list(range(model.num_classes))

    labels = []
    for c in classes_to_generate:
        labels.extend([c] * per_class)

    imgs, trace = generate_ff_images(
        model,
        target_labels=labels,
        steps=steps,
        lr=lr,
        tv_weight=tv_weight,
        l2_weight=l2_weight,
        init="noise",
        img_h=img_h,
        img_w=img_w,
        verbose=True
    )

    nrow = per_class
    title = f"FF generations | steps={steps}, lr={lr}, tv={tv_weight}, l2={l2_weight}"
    if show:
        show_image_grid(imgs, nrow=nrow, title=title)
    save_image_grid(imgs, nrow=nrow, save_path=save_path)
    print(f"[Saved] {save_path}")

    return imgs, trace


if __name__ == "__main__":
    main()